# trgr5899
Hashing Implementation and Analysis
	Our class was tasked with creating hash tables for two completely different data sets.
  In doing this, chaining with linked lists, chaining with binary search trees, linear probing, and Cuckoo hashing, 
  which are various collision resolution methods, were used. After the hash tables were created, performance evaluations 
  were run on each method to determine which was the most efficient when increasing the load factor on the hash table.

Purpose: In the real world, knowing how much time inserting, deleting, and searching a specific data
structure will take is highly valued. Due to the fact that many businesses have millions upon millions of data 
files which need to be manipulated very quickly, performance evaluations are commonly run, which is why the hash tables
were tested. The test consisted of measuring the time it took for each collision resolution method to insert, delete, and search 
the hash table 100 times, while being under varying load factors ranging between 0 and 1.0.

Procedure: All of the collision resolution functions can have widely different implementations; for example, though they all use the same two hash functions (key%table size and floor(key/table size)) to determine which index the value would go into for each hash table, they are implemented differently.
Chaining with a linked list used a pointer, which pointed to an array of linked lists, and each index was its own linked list. The linked list was created using a struct named node containing a key and a pointer to the next node. Chaining with a binary search tree (BST) was similar to a linked list, because it used a pointer, but this pointer pointed to an array of pointers, which then pointed to a BST.  The BST was developed by using a struct named Node which had a key value along with two different pointers, the left and right children, which pointed to other Nodes. 
Linear probing was the most simple since it only used an array of integers, and each index was initialized to be -1. While using linear probing the first step was to put the key value into the correct hash function, and then into the corresponding index of the hash table. If a collision occurred then the key value would be placed in the next available index. 
Cuckoo hashing used two integer arrays which used different hash functions, and each indices were initialized to -1. The function would start out by getting the index from the first hash function and checking the first hash table to see if that index already had a key value in it. If it did not, then the value would be inserted there, but if so then it was moved to the second hash table. In the second hash table it checked if the index from the second hash function already had a value.  If it did not then the value was inserted there, and if it did then it went back to the first hash table to place the value into its corresponding index, and take the value that was already there. The next step was to check the replaced values index for the second hash table, and if its index already had a value then the process was repeated. If the value being replaced was the same as the initial value that was being replaced in the beginning, this indicated that there was an infinite loop in the algorithm. This could be fixed by changing the table size of both hash tables and attempting to re-insert all the values until they all fit into the tables. This could be easily achieved by creating a recursive helper function for the insert, which would keep calling itself until all the values found an empty index.
	The performance was tested using each technique by using the function chrono from the chrono library. The time before an insert, delete, and search was measured, then after the function was complete the time was measured again. This allowed a measure of the total elapsed time to be recorded down to nanoseconds. This data was collected using 100 iterations of each function, inserting, deleting, and searching, and each functions performance time was averaged. Then, an overall average of all 100 iterations for each function was calculated to get an overall performance in seconds. Cuckoo hashing was also tested with chrono, though the results seemed insignificant. Thus, it was more beneficial to test its performance by comparing the load factor to the number of times the value had to be resized.


Results: Overall, the implementations worked very well with the exception of cuckoo hashing. As can be told from the graphs below, the chaining using linked list and hash function 1 were never greater than 0 nanoseconds. Hash function 2 ended up having the slowest average performance out of all the methods (0.00187 seconds), which occurred when using data set 2 and was likely due to the way that the data was more condensed into certain ranges. This caused some of the linked lists to become very large.
BST was by far the most efficient method, which practically never had an average time greater than 0 nanoseconds for both hash functions and data sets. The different set of data did not affect its efficiency at all. This was likely due to the fact that a balanced BST has a big o complexity of O(logn) which is already very competent. 
 Linear probing also performed very well, with the longest average time being 0.0000166 seconds. Overall, the data sets both had the same performance, and since linear probing is not very complex it is usually not hard to find desired values no matter how the data is inserted.
Finally, Cuckoo hashing was not efficient at all. Even though the function time never exceeded 0 nanoseconds, the load factors could not get very high. The function often ran into cycles which meant restarting both hash functions. This caused the program to go into infinite loops, making the performance poor. Data set 1 seemed to perform better since the table was able to reach much higher load factors of 0.055, and data set 2 only reached 0.029. Since data set 1 was more scattered it was less likely to have a collision, inturn not causing the hash table to have to be resized.  

	The objective of this project was to test the performance of several different hashing techniques in order to make claims about 
  how well each operates given different data. It was concluded that cuckoo hashing was not an efficient option for either data set, 
  and that chaining with a linked list, chaining with a BST, and linear probing were are all viable options
  for data sets which are very scattered and diverse. On the other hand, if provided data is very similar and condensed, then
  it would be wise to use chaining with a BST or linear probing.
